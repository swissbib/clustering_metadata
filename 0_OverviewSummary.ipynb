{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Deduplication of Swissbib Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Program** Applied Data Science : Machine Learning<br>\n",
    "**Institution** EPFL Extension School<br>\n",
    "**Course** \\#5, Capstone Project<br><br>\n",
    "**Title** Deduplication of Swissbib Raw Data<br>\n",
    "**Author** Andreas Jud<br>\n",
    "**Date** dd-MAR-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "    - [Requirements](#Requirements)\n",
    "    - [Thanks](#Thanks)\n",
    "- [Structure of the Project](#Structure-of-the-Project)\n",
    "- [Runs and Results](#Runs-and-Results)\n",
    "    - [Runtime Parameters](#Runtime-Parameters)\n",
    "    - [Overview of Runs](#Overview-of-Runs)\n",
    "    - [Runs Execution](#Runs-Execution)\n",
    "- [Assessment of Results](#Assessment-of-Results)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Proposal](./project-proposal-andreas-jud.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This capstone project uses several publically available python libraries. The chapters where a library is needed show the\n",
    "<br>$\\texttt{! pip install <library name>}$<br>\n",
    "command in a separate code cell, respectively. These commands have been executed once for the development environment of the author and have been commented out for later execution runs in order to produce more readable notebooks. For executing the set of notebooks of the capstone project on a python development environment with a basic setup, a [requirements.txt](./requirements.txt) file has been written. This file will be executed in the code cell below and installs the library packages needed for this capstone project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook of the capstone project consists of the following chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Data Analysis](./1_DataAnalysis.ipynb)\n",
    "1. [Goldstandard and Data Preparation](./2_GoldstandardDataPreparation.ipynb)\n",
    "1. [Data Synthesizing](./3_DataSynthesizing.ipynb)\n",
    "1. [Feature Matrix Generation](./4_FeatureMatrixGeneration.ipynb)\n",
    "1. [Features Discussion and Dummy Classifier Baseline](./5_FeatureDiscussionDummyBaseline.ipynb)\n",
    "1. [Decision Tree Model](./6_DecisionTreeModel.ipynb)\n",
    "1. [Support Vector Classifier Model](./7_SVCModel.ipynb)\n",
    "1. [Neural Network Model](./8_NeuralNetwork.ipynb)\n",
    "\n",
    "Appendix\n",
    "\n",
    "- [A. References](./A_References.ipynb)\n",
    "- [B. Comparison of Similarity Metrics](./B_CompareSimilarities.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section starts with explaining the runtime parameters with which the notebooks of the capstone project can be called. After the parameter space has been settled, a series of runs will be executed with different parameter values each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebooks of this capstone project can be called with six specific global parameters. These parameters are listed and explained here.\n",
    "\n",
    "- $\\texttt{execution}\\_\\texttt{mode}$ - The reason for introducing this parameter has been runtime of execution. For the models, grid search has been implemented with the goal to find the best parameters for a model. The bigger the grid space, i.e. the more points it has for each of its dimensions, the longer the runtime of a notebook lasts. Oversampling of records of duplicates intreases the runtime of a notebook, too. When searching the best parameters for a model, the grid space has to be scanned widely. The runtime of the model may extend to hours, for such calculations. For some runs, smaller grid spaces may be sufficient. In order to save calculation time, a restricted grid space can be chosen. The execution mode of a notebook may have three distinct values.\n",
    "    - Mode $\\texttt{full}$ will be used for executing the notebook, calling it in this very chapter and collecting the results of each notebook for final comparison and assessment.\n",
    "    - Mode $\\texttt{restricted}$ will mainly, but not exclusively be used for executing the notebook locally, i.e. opening it manually and running it cell by cell. The original purpose of this mode of execution has been to open the notebook and read its text, in order to focus on the contents and specific explanation for a model. Runtime is supposed to be short for these execution modes. The grid parameters chosen for this mode have flowed back from the insights found from results with full execution mode of this chapter.\n",
    "    - Mode $\\texttt{tune}$ will be used for a final fine tuning of the models' parameters. Goal of a mode $\\texttt{tune}$ run is to get the best models of a grid space close to a precalculated best model of the wide grid space. While mode $\\texttt{full}$ will be used for scanning a wide range of orders of magnitude of the parameter space, mode $\\texttt{tune}$ will be used for scanning the neighbouring parameter points of the best models of the mode $\\texttt{full}$ run. This approach is an iterative search for the best parameters of the models.\n",
    "- $\\texttt{oversampling}$ - The number of records of duplicates generated with Swissbib's goldstandard data has been low compared to the number of records with uniques. The effect has been to generally use balancing for model fitting. In order to increase the ratio of duplicates in the training and testing data, an oversampling with synthetic data has been tried. To control the ratio, parameter $\\texttt{oversampling}$ has been introduced. Synthetic data will be multiplyed with a for loop, so to reach a ratio of oversampling in percent (%) in the final data set for model calculation. If $\\texttt{oversampling}=0$, no synthetic data will be added to the goldstandard data. This parameter will be used in chapter [Data Synthesizing](./3_DataSynthesizing.ipynb).\n",
    "- $\\texttt{modification}\\_\\texttt{ratio}$ - This parameter will be used in chapter [Data Synthesizing](./3_DataSynthesizing.ipynb), too. In that chapter, some specific kinds of data modification (typos) to be simulated have been defined for each attribute. If an attribute shows one or more kinds of modification, this parameter controls the ratio and therefore the amount of records with modification.\n",
    "- $\\texttt{factor}$ - In Swissbib's raw data, records may have missing values in attributes. When building pairs of records for generating the feature matrix, records may occur with a value on both sides of a pair, but also with missing values on one side of a pair and even with missing values on both sides of a pair, see chapters [Feature Matrix Generation](./4_FeatureMatrixGeneration.ipynb) and [Features Discussion and Dummy Classifier Baseline](./5_FeatureDiscussionDummyBaseline.ipynb) for a deeper discussion. Missing values may influence the model. For that reason, a decision has been taken to mark the features of records of pairs with missing attribute values. One way of marking them can be to transform them to a negative similarity value. During implementation, a discussion has been on how the distance from the origin (similarity value of 0) on the negative similarity side would influence a model, especially a Neural Network, due to its linear dependency on firing of a node. To be able to set the distance from the origin, this factor has been introduced. In the implemented code, the factor ...\n",
    "    - multiplies -0.5 if one attribute of the pair is missing.\n",
    "    - multiplies -1.0 if both attributes of the paire are missing.\n",
    "- $\\texttt{mode}\\_\\texttt{exactDate}$ - The basic similarity metric of attribute $\\texttt{exact}\\_\\texttt{date}$, undergoes some modification in presence of unknown values, see chapter [Feature Matrix Generation](./4_FeatureMatrixGeneration.ipynb) for implementation details. Two different modes of modifying the basic similarity metric have been implemented. To decide on one mode of modification, parameter $\\texttt{exact}\\_\\texttt{date}$ has been introduced. \n",
    "- $\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}$ - Swissbib's raw data bring attributes $\\texttt{scale}$, $\\texttt{part}$, and $\\texttt{volumes}$ as full-text strings. Swissbib's deduplication engine extracts their number digit parts in a preprocessing step with the goal to generate more reliable results. A very basic stripping function has been implemented in this capstone project with the goal to copy Swissbib's more sophisticated logic. The model result may change as a function of the similarity values of these three attributes. To assess the effect of stripping the attributes values, parameter $\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}$ will be used for switching on ($\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}=\\texttt{True}$) and off ($\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}=\\texttt{False}$) the stripping to number digits logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the notebooks of the capstone project, functions of python library $\\texttt{nbparameterise}$ will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nbparameterise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the description of the runtime parameters, a multi-dimensional space of calculation options has been spanned. Due to limited calculation power based on restricted resources, it has appeared to be important to design the runs to be done well to reduce unnecessary calculation time and to increase the statements of the documented runs. The strategy used for the runs of this capstone project is shown in the table below. This strategy with its specific parameters has grown in the course of the capstone project iteratively. Many non-documented runs have been done with the models up to a point where the author had reached a feeling for the basic behaviour of a model linked to its best-suited parameter space. In the end, this chapter condenses the author's learning with the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| run id | description | parameter set |\n",
    "| :----: | :---------- | :--------- |\n",
    "| 0 | Goldstandard sampling,<br>**full feature modification** | $\\texttt{execution}\\_\\texttt{mode}$ = $\\texttt{full}$<br>$\\texttt{oversampling}$ = $\\texttt{None}$ with $\\texttt{modification}\\_\\texttt{ratio}$ = \\< irrelevant \\><br>$\\texttt{factor}$ = $0.1$<br>$\\texttt{mode}\\_\\texttt{exactDate}$ = $\\texttt{xor}$ and $\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}$ = $\\texttt{True}$ |\n",
    "| 1 | Goldstandard sampling,<br>**little feature modification** | $\\texttt{execution}\\_\\texttt{mode}$ = $\\texttt{restricted}$<br>$\\texttt{oversampling}$ = $\\texttt{None}$ with $\\texttt{modification}\\_\\texttt{ratio}$ = \\< irrelevant \\><br>$\\texttt{factor}$ = $0.1$<br><font color='red'>$\\texttt{mode}\\_\\texttt{exactDate}$ = $\\texttt{added}\\_\\texttt{u}$ and $\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}$ = $\\texttt{False}$</font> |\n",
    "| 2 | Goldstandard sampling,<br>**full missing separation** | $\\texttt{execution}\\_\\texttt{mode}$ = $\\texttt{restricted}$<br>$\\texttt{oversampling}$ = $\\texttt{None}$ with $\\texttt{modification}\\_\\texttt{ratio}$ = \\< irrelevant \\><br><font color='red'>$\\texttt{factor}$ = $1.0$</font><br>$\\texttt{mode}\\_\\texttt{exactDate}$ = $\\texttt{added}\\_\\texttt{u}$ and $\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}$ = $\\texttt{True}$ |\n",
    "| 3 | **Oversampling** | $\\texttt{execution}\\_\\texttt{mode}$ = $\\texttt{full}$<br><font color='red'>$\\texttt{oversampling}$ = $\\texttt{20}$ with $\\texttt{modification}\\_\\texttt{ratio}$ = $0.2$</font><br>$\\texttt{factor}$ = $0.1$<br>$\\texttt{mode}\\_\\texttt{exactDate}$ = $\\texttt{added}\\_\\texttt{u}$ and $\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}$ = $\\texttt{True}$ |\n",
    "| 4 | Final fine tuning | <font color='red'>$\\texttt{execution}\\_\\texttt{mode}$ = $\\texttt{tune}$</font><br>$\\texttt{oversampling}$ = $\\texttt{None}$ with $\\texttt{modification}\\_\\texttt{ratio}$ = \\< irrelevant \\><br>$\\texttt{factor}$ = $0.1$<br>$\\texttt{mode}\\_\\texttt{exactDate}$ = $\\texttt{xor}$ and $\\texttt{strip}\\_\\texttt{number}\\_\\texttt{digits}$ = $\\texttt{True}$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy can be described as following.\n",
    "1. run - find best models.\n",
    "1. run - play with feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the run can be executed, the global parameters describe in subsection [Runtime Parameters](#Runtime-Parameters) have to be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for run 0 : \n",
      " {'em': 'restricted', 'os': 0, 'mr': 0.2, 'fa': 0.1, 'me': 'xor', 'sn': True, 'notebook_name': ''}\n",
      "Parameters for run 1 : \n",
      " {'em': 'restricted', 'os': 0, 'mr': 0.2, 'fa': 0.1, 'me': 'added_u', 'sn': False, 'notebook_name': ''}\n",
      "Parameters for run 2 : \n",
      " {'em': 'restricted', 'os': 0, 'mr': 0.2, 'fa': 1.0, 'me': 'xor', 'sn': True, 'notebook_name': ''}\n",
      "Parameters for run 3 : \n",
      " {'em': 'full', 'os': 20, 'mr': 0.2, 'fa': 0.1, 'me': 'xor', 'sn': True, 'notebook_name': ''}\n",
      "Parameters for run 4 : \n",
      " {'em': 'tune', 'os': 0, 'mr': 0.2, 'fa': 0.1, 'me': 'xor', 'sn': True, 'notebook_name': ''}\n"
     ]
    }
   ],
   "source": [
    "# Generate dictionary for parameter handover\n",
    "runtime_param_dict = {\n",
    "#    'em' : 'full' #execution_mode : ['restricted', 'full', 'tune']\n",
    "    'em' : 'restricted' #execution_mode : ['restricted', 'full', 'tune']\n",
    "    , 'os' : 0 # oversampling : [0, 20]\n",
    "    , 'mr' : 0.2 # modification_ratio\n",
    "    , 'fa' : 0.1 # factor : [0.1, 1.0]\n",
    "    , 'me' : 'xor' # mode_exactDate : ['added_u', 'xor']\n",
    "    , 'sn' : True # strip_number_digits : [True, False]\n",
    "    , 'notebook_name' : ''\n",
    "}\n",
    "# Run id = 0\n",
    "runtime_param_dict_list = [runtime_param_dict]\n",
    "\n",
    "# Run id = 1\n",
    "runtime_param_dict = runtime_param_dict.copy()\n",
    "runtime_param_dict['em'] = 'restricted'\n",
    "runtime_param_dict['me'] = 'added_u'\n",
    "runtime_param_dict['sn'] = False\n",
    "runtime_param_dict_list.append(runtime_param_dict)\n",
    "\n",
    "# Run id = 2\n",
    "runtime_param_dict = runtime_param_dict.copy()\n",
    "runtime_param_dict['fa'] = 1.0\n",
    "runtime_param_dict['me'] = 'xor'\n",
    "runtime_param_dict['sn'] = True\n",
    "runtime_param_dict_list.append(runtime_param_dict)\n",
    "\n",
    "# Run id = 3\n",
    "runtime_param_dict = runtime_param_dict.copy()\n",
    "runtime_param_dict['em'] = 'full'\n",
    "runtime_param_dict['fa'] = 0.1\n",
    "runtime_param_dict['os'] = 20\n",
    "runtime_param_dict_list.append(runtime_param_dict)\n",
    "\n",
    "# Run id = 4\n",
    "runtime_param_dict = runtime_param_dict.copy()\n",
    "runtime_param_dict['em'] = 'tune'\n",
    "runtime_param_dict['os'] = 0\n",
    "runtime_param_dict_list.append(runtime_param_dict)\n",
    "\n",
    "# Let's have a look at the predefined parameters\n",
    "for run in range(len(runtime_param_dict_list)):\n",
    "    print('Parameters for run', run, ': \\n', runtime_param_dict_list[run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations of the notebooks can be done with the parameter specified by the list of dictionaries $\\texttt{runtime}\\_\\texttt{param}\\_\\texttt{dict}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run number 0\n",
      "Executing notebook 2_GoldstandardDataPreparation.ipynb\n",
      "Executing notebook 3_DataSynthesizing.ipynb\n",
      "Executing notebook 4_FeatureMatrixGeneration.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "import nbparameterise as nbp\n",
    "import os\n",
    "import results_saving_funcs as rsf\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "path_results = './results'\n",
    "\n",
    "# Determine all relenvant notebooks, ommit Overview Summary and Appendixes\n",
    "a = ! ls [2-9]_* | grep .ipynb\n",
    "\n",
    "for run in range(len(runtime_param_dict_list)):\n",
    "    print('Run number', run)\n",
    "    for i in range(len(a)):\n",
    "        print('Executing notebook', a[i])\n",
    "        with open(a[i]) as notebook:\n",
    "            nb = nbformat.read(notebook, as_version=4)\n",
    "\n",
    "            # Get list of parameter objects\n",
    "            orig_parameters = nbp.extract_parameters(nb)\n",
    "            # Update parameters\n",
    "            params = nbp.parameter_values(orig_parameters,\n",
    "                                          execution_mode=runtime_param_dict_list[run]['em'],\n",
    "                                          oversampling=runtime_param_dict_list[run]['os'],\n",
    "                                          modification_ratio = runtime_param_dict_list[run]['mr'],\n",
    "                                          factor=runtime_param_dict_list[run]['fa'],\n",
    "                                          exactDate_mode = runtime_param_dict_list[run]['me'],\n",
    "                                          strip_number_digits = runtime_param_dict_list[run]['sn']\n",
    "                                         )\n",
    "            # Make notebook object with these definitions, ...\n",
    "            nb = nbp.replace_definitions(nb, params, execute=False)\n",
    "\n",
    "            ep = ExecutePreprocessor(timeout=None)\n",
    "            # ... and execute it.\n",
    "            ep.preprocess(nb, {\"metadata\": {\"path\": './'}})\n",
    "        # Save notebook run in result file\n",
    "        runtime_param_dict.update({'notebook_name' : a[i]})\n",
    "        rsf.save_notebook_results(nb, path_results, runtime_param_dict_list[run])\n",
    "\n",
    "    # Assessment of run\n",
    "    ### HIER MUSS DER DATEINAME RUN-ABHÄNGIG GEMACHT WERDEN.\n",
    "    results = rsf.restore_dict_results(path_results, 'results.pkl')\n",
    "    ### /HIER MUSS DER DATEINAME RUN-ABHÄNGIG GEMACHT WERDEN.\n",
    "\n",
    "    results['results_best_model'].reset_index(drop=True, inplace=True)\n",
    "    # Ranking metric according to chapter 6 : roc auc\n",
    "    results['results_best_model'].sort_values('auc', ascending=False)\n",
    "\n",
    "    pd.options.display.max_rows = 200\n",
    "\n",
    "    # For timestamp in filename\n",
    "    tmstmp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    for classifier in results['results_model_scores'].keys() :\n",
    "        print(f'\\n{classifier}')\n",
    "        display(results['results_model_scores'][classifier].head(20))\n",
    "        results['results_model_scores'][classifier].to_csv(os.path.join(path_results, classifier + '_'\n",
    "                                                                        + tmstmp + '.csv'), index=False)\n",
    "\n",
    "print('Done with all runs of all notebooks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read confusion matrix results from chapters\n",
    "wrong_predictions = rsf.restore_dict_results(path_goldstandard, 'wrong_predictions.pkl')\n",
    "\n",
    "wrong_prediction_groups = ['false_predicted_uniques', 'false_predicted_duplicates']\n",
    "fpu, fpd = {}, {}\n",
    "\n",
    "for i in wrong_predictions.keys() :\n",
    "    fpu[i] = wrong_predictions[i][wrong_prediction_groups[0]].sort_index().index.tolist()\n",
    "    fpd[i] = wrong_predictions[i][wrong_prediction_groups[1]].sort_index().index.tolist()\n",
    "\n",
    "print(wrong_prediction_groups[0])\n",
    "for i in fpu.keys() :\n",
    "    print(i, len(fpu[i]), '\\n', fpu[i])\n",
    "print('')\n",
    "print(wrong_prediction_groups[1])\n",
    "for i in fpd.keys() :\n",
    "    print(i, len(fpd[i]), '\\n', fpd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore DataFrame with attributes and similarity values\n",
    "df_attribute_with_sim_feature = pd.read_pickle(os.path.join(\n",
    "    path_goldstandard, 'labelled_feature_matrix_full.pkl'), compression=None)\n",
    "\n",
    "# Binary intermediary DataFrame file for docid's\n",
    "df_index_docids = pd.read_pickle(os.path.join(\n",
    "    path_goldstandard, 'index_docids_df.pkl'), compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 200\n",
    "\n",
    "df_attribute_with_sim_feature.iloc[fpu[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index_docids.iloc[fpu[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
